算法的时间复杂度，用来度量算法的运行时间，记作: T(n) = O(f(n))。它表示随着 输入大小n 的增大，算法执行需要的时间的增长速度可以用 f(n) 来描述

一个算法的执行次数是 T(n)，那么只保留最高次项，同时忽略最高项的系数后得到函数 f(n)，此时算法的时间复杂度就是 O(f(n))。为了方便描述，下文称此为 大O推导法。

对于条件判断语句，总的时间复杂度等于其中 时间复杂度最大的路径 的时间复杂度。

T(n) = n^3 + n^2 + 29，此时时间复杂度为 O(n^3)。
T(n) = 3n^3，此时时间复杂度为 O(n^3)。

for (int i = 0; i < n; i++) {
for (int j = i; j < n; j++) {
printf("Hello World\n");
}
}
当 i = 0 时，内循环执行 n 次运算，当 i = 1 时，内循环执行 n - 1 次运算……当 i = n - 1 时，内循环执行 1 次运算。
所以，执行次数 T(n) = n + (n - 1) + (n - 2)……+ 1 = n(n + 1) / 2 = n^2 / 2 + n / 2。
根据上文说的 大O推导法 可以知道，此时时间复杂度为 O(n^2)。


递归的时间复杂度算法，可以把每次递归单独计算然后累加到一起
比如每次递归都是 O(1)
则 T(n) = O(1) + O(1) + O(1) + O(1)
= O(n)